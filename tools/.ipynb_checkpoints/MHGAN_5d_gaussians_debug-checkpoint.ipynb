{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn.datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import time\n",
    "import random\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch, torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch import autograd\n",
    "\n",
    "from paths import (path_to_save_remote, \n",
    "                   path_to_save_local,\n",
    "                   port_to_remote)\n",
    "\n",
    "from params_5d_gaussians import (random_seed,\n",
    "                                 batch_size,\n",
    "                                 num_samples_in_cluster,\n",
    "                                 dim,\n",
    "                                 num_gaussian_per_dim,\n",
    "                                 coord_limits,\n",
    "                                 sigma, \n",
    "                                 train_dataset_size,\n",
    "                                 n_dim,\n",
    "                                 n_layers_d,\n",
    "                                 n_layers_g,\n",
    "                                 n_hid_d,\n",
    "                                 n_hid_g,\n",
    "                                 n_out,\n",
    "                                 normalize_to_0_1,\n",
    "                                 loss_type,\n",
    "                                 lr_init,\n",
    "                                 betas,\n",
    "                                 use_gradient_penalty,\n",
    "                                 Lambda,\n",
    "                                 num_epochs,\n",
    "                                 num_epoch_for_save,\n",
    "                                 batch_size_sample,\n",
    "                                 k_g,\n",
    "                                 k_d,\n",
    "                                 mode,\n",
    "                                 proj_list,\n",
    "                                 n_calib_pts,\n",
    "                                 plot_mhgan,\n",
    "                                 device)\n",
    "from utils import (prepare_gaussians, \n",
    "                   prepare_train_batches,\n",
    "                   prepare_dataloader, \n",
    "                   logging)\n",
    "\n",
    "from gan_fc_models import (Generator_fc, \n",
    "                           Discriminator_fc, \n",
    "                           weights_init_1, \n",
    "                           weights_init_2)\n",
    "\n",
    "from gan_train import train_gan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = prepare_gaussians(num_samples_in_cluster = num_samples_in_cluster, \n",
    "                            dim = dim, \n",
    "                            num_gaussian_per_dim = num_gaussian_per_dim, \n",
    "                            coord_limits = coord_limits, \n",
    "                            sigma = sigma,\n",
    "                            random_seed = random_seed)\n",
    "scaler = None \n",
    "train_dataloader = prepare_dataloader(X_train, batch_size, \n",
    "                                      random_seed=random_seed)\n",
    "\n",
    "G = Generator_fc(n_dim=n_dim, \n",
    "                 n_layers=n_layers_g,\n",
    "                 n_hid=n_hid_g,\n",
    "                 n_out=n_out,\n",
    "                 non_linear=nn.ReLU(),\n",
    "                 device=device).to(device)\n",
    "D = Discriminator_fc(n_in=n_dim, \n",
    "                     n_layers=n_layers_d,\n",
    "                     n_hid=n_hid_d,\n",
    "                     non_linear=nn.ReLU(),\n",
    "                     device=device).to(device)\n",
    "G.init_weights(weights_init_2, random_seed=random_seed)\n",
    "D.init_weights(weights_init_2, random_seed=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(243000, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start to do MH sampling....\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-e88efa18b0db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Start to do MH sampling....\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mtype_calibrator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'iso'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m X_mh = mh_sampling(X_train_scale, \n\u001b[0m\u001b[1;32m     11\u001b[0m                    \u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                    \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/myenv/lib/python3.8/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gans-mcmc/tools/mh_2d_sampling.py\u001b[0m in \u001b[0;36mmh_sampling\u001b[0;34m(X_train, G, D, device, n_calib_pts, batch_size_sample, normalize_to_0_1, type_calibrator)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0;31m#                           dump_fname=score_fname)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[0mpred_df_dump\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf_df\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m         discriminator_analysis(scores_fake_df, scores_real_df, ref_method,\n\u001b[0m\u001b[1;32m    237\u001b[0m                                 calib_dict=calib_dict)\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gans-mcmc/tools/mhgan_utils.py\u001b[0m in \u001b[0;36mdiscriminator_analysis\u001b[0;34m(scores_fake_df, scores_real_df, ref_method, calib_dict, dump_fname, label)\u001b[0m\n\u001b[1;32m     66\u001b[0m     '''\n\u001b[1;32m     67\u001b[0m     \u001b[0;31m# Build combined data set dataframe and train calibrators\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     pred_df, y_true = cl.combine_class_df(neg_class_df=scores_fake_df,\n\u001b[0m\u001b[1;32m     69\u001b[0m                                           pos_class_df=scores_real_df)\n\u001b[1;32m     70\u001b[0m     pred_df, y_true, clf_df = cl.calibrate_pred_df(pred_df, y_true, \n",
      "\u001b[0;32m~/gans-mcmc/tools/classification.py\u001b[0m in \u001b[0;36mcombine_class_df\u001b[0;34m(neg_class_df, pos_class_df)\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg_class_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_class_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;31m# Note nec always the case, but for now let's require balance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg_class_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_class_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mLABEL\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mneg_class_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from mh_2d_sampling import mh_sampling\n",
    "\n",
    "if scaler is not None:\n",
    "    X_train_scale = scaler.transform(X_train)\n",
    "else:\n",
    "    X_train_scale = X_train\n",
    "\n",
    "print(\"Start to do MH sampling....\")\n",
    "type_calibrator = 'iso'\n",
    "X_mh = mh_sampling(X_train_scale, \n",
    "                   G, \n",
    "                   D, \n",
    "                   G.device, \n",
    "                   n_calib_pts, \n",
    "                   batch_size_sample=batch_size_sample,\n",
    "                   normalize_to_0_1=normalize_to_0_1,\n",
    "                   type_calibrator=type_calibrator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mh\n",
    "import classification as cl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "from scipy.special import expit\n",
    "\n",
    "\n",
    "def discriminator_analysis(scores_fake_df, scores_real_df, ref_method,\n",
    "                           calib_dict,\n",
    "                           dump_fname=None,\n",
    "                           label='label'):\n",
    "    '''\n",
    "    scores_fake_df : DataFrame, shape (n, n_discriminators)\n",
    "    scores_real_df : DataFrame, shape (n, n_discriminators)\n",
    "    ref_method : (str, str)\n",
    "    perf_report : str\n",
    "    calib_report : str\n",
    "    clf_df : DataFrame, shape (n_calibrators, n_discriminators)\n",
    "    '''\n",
    "    # Build combined data set dataframe and train calibrators\n",
    "    pred_df, y_true = cl.combine_class_df(neg_class_df=scores_fake_df,\n",
    "                                          pos_class_df=scores_real_df)\n",
    "    pred_df, y_true, clf_df = cl.calibrate_pred_df(pred_df, y_true, \n",
    "                                                   calibrators=calib_dict)\n",
    "    # Make methods flat to be compatible with benchmark tools\n",
    "    pred_df.columns = cl.flat_cols(pred_df.columns)\n",
    "    ref_method = cl.flat(ref_method)  # Make it flat as well\n",
    "\n",
    "    # Do calibration analysis\n",
    "    #Z = cl.calibration_diagnostic(pred_df, y_true)\n",
    "    #calib_report = Z.to_string()\n",
    "\n",
    "    # Dump prediction to csv in case we want it for later analysis\n",
    "    if dump_fname is not None:\n",
    "        pred_df_dump = pd.DataFrame(pred_df, copy=True)\n",
    "        pred_df_dump[label] = y_true\n",
    "        pred_df_dump.to_csv(dump_fname, header=True, index=False)\n",
    "    \n",
    "    return pred_df, clf_df\n",
    "    # No compute report on performance of each discriminator:\n",
    "    # Make it into log-scale cat distn for use with benchmark tools\n",
    "    #pred_df = cl.binary_pred_to_one_hot(pred_df, epsilon=1e-12)\n",
    "    #print(y_true)\n",
    "    #print(pred_df)\n",
    "    #perf_df, _ = btc.summary_table(pred_df, y_true,\n",
    "    #                               btc.STD_CLASS_LOSS, btc.STD_BINARY_CURVES,\n",
    "    #                               ref_method=ref_method)\n",
    "\n",
    "    #crap_lim = const_dict(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_scores(scores):\n",
    "    assert isinstance(scores, dict)\n",
    "    for sv in scores.values():\n",
    "        assert isinstance(sv, np.ndarray)\n",
    "        assert sv.dtype.kind == 'f'\n",
    "        assert sv.ndim == 1\n",
    "        assert np.all(0 <= sv) and np.all(sv <= 1)\n",
    "    scores = pd.DataFrame(scores)\n",
    "    return scores\n",
    "\n",
    "def validate_X(X):\n",
    "    assert isinstance(X, np.ndarray)\n",
    "    assert X.dtype.kind == 'f'\n",
    "    batch_size, dim = X.shape\n",
    "    assert X.shape == (batch_size, dim)\n",
    "    assert np.all(np.isfinite(X))\n",
    "    return X\n",
    "\n",
    "def validate(R):\n",
    "    '''\n",
    "    X : ndarray, shape (batch_size, nc, image_size, image_size)\n",
    "    scores : dict of str -> ndarray of shape (batch_size,)\n",
    "    '''\n",
    "    X, scores = R\n",
    "    X = validate_X(X)\n",
    "    scores = validate_scores(scores)\n",
    "    assert len(X) == len(scores)\n",
    "    return X, scores\n",
    "\n",
    "def batched_gen_and_disc(gen_and_disc, n_batches, batch_size):\n",
    "    '''\n",
    "    Get a large batch of images. Pytorch might run out of memory if we set\n",
    "    the batch size to n_images=n_batches*batch_size directly.\n",
    "    g_d_f : callable returning (X, scores) compliant with `validate`\n",
    "    n_images : int\n",
    "        assumed to be multiple of batch size\n",
    "    '''\n",
    "    X, scores = zip(*[validate(gen_and_disc(batch_size))\n",
    "                      for _ in range(n_batches)])\n",
    "    X = np.concatenate(X, axis=0)\n",
    "    scores = pd.concat(scores, axis=0, ignore_index=True)\n",
    "    return X, scores\n",
    "\n",
    "def enhance_samples(scores_df, scores_max, scores_real_df, clf_df,\n",
    "                    pickers):\n",
    "    '''\n",
    "    Return selected image (among a batcf on n images) for each picker.\n",
    "    scores_df : DataFrame, shape (n, n_discriminators)\n",
    "    scores_real_df : DataFrame, shape (m, n_discriminators)\n",
    "    clf_df : Series, shape (n_classifiers x n_calibrators,)\n",
    "    pickers : dict of str -> callable\n",
    "    '''\n",
    "    assert len(scores_df.columns.names) == 1\n",
    "    assert list(scores_df.columns) == list(scores_real_df.columns)\n",
    "\n",
    "    init_idx = np.random.choice(len(scores_real_df))\n",
    "\n",
    "    picked = pd.DataFrame(data=0, index=pickers.keys(), columns=clf_df.index,\n",
    "                          dtype=int)\n",
    "    cap_out = pd.DataFrame(data=False,\n",
    "                           index=pickers.keys(), columns=clf_df.index,\n",
    "                           dtype=bool)\n",
    "    alpha = pd.DataFrame(data=np.nan,\n",
    "                         index=pickers.keys(), columns=clf_df.index,\n",
    "                         dtype=float)\n",
    "    for disc_name in sorted(scores_df.columns):\n",
    "        assert isinstance(disc_name, str)\n",
    "        s0 = scores_real_df[disc_name].values[init_idx]\n",
    "        assert np.ndim(s0) == 0\n",
    "        for calib_name in sorted(clf_df[disc_name].index):\n",
    "            assert isinstance(calib_name, str)\n",
    "            #print(f\"calibrator name = {calib_name}, discriminator name = {disc_name}\")\n",
    "            calibrator = clf_df[(disc_name, calib_name)]\n",
    "            s_ = np.concatenate(([s0], scores_df[disc_name].values))\n",
    "            s_ = calibrator.predict(s_)\n",
    "            s_max, = calibrator.predict(np.array([scores_max[disc_name]]))\n",
    "            for picker_name in sorted(pickers.keys()):\n",
    "                assert isinstance(picker_name, str)\n",
    "                #print(f\"picker name = {picker_name}\")\n",
    "                idx, aa = pickers[picker_name](s_, score_max=s_max)\n",
    "\n",
    "                if idx == 0:\n",
    "                    # Try again but init from first fake\n",
    "                    cap_out.loc[picker_name, (disc_name, calib_name)] = True\n",
    "                    idx, aa = pickers[picker_name](s_[1:], score_max=s_max)\n",
    "                else:\n",
    "                    idx = idx - 1\n",
    "                assert idx >= 0\n",
    "\n",
    "                picked.loc[picker_name, (disc_name, calib_name)] = idx\n",
    "                alpha.loc[picker_name, (disc_name, calib_name)] = aa\n",
    "    \n",
    "    return picked, cap_out, alpha\n",
    "\n",
    "def enhance_samples_series(g_d_f, scores_real_df, clf_df,\n",
    "                           pickers, n_samples=16,\n",
    "                           batch_size = 16,\n",
    "                           chain_batches = 10,\n",
    "                           max_est_batches = 156):\n",
    "    '''\n",
    "    Call enhance_samples multiple times to build up a batch of selected images.\n",
    "    Stores list of used images X separate from the indices of the images\n",
    "    selected by each method. This is more memory efficient if there are\n",
    "    duplicate images selected.\n",
    "    g_d_f : callable returning (X, scores) compliant with `validate`\n",
    "    calibrator : dict of str -> trained sklearn classifier\n",
    "        same keys as scores\n",
    "    n_images : int\n",
    "    '''\n",
    "    #batch_size = 16   # Batch size to use when calling the pytorch generator G\n",
    "    #chain_batches = 10  # Number of batches to use total for the pickers\n",
    "    #max_est_batches = 156  # Num batches for estimating M in DRS pilot samples\n",
    "\n",
    "    assert n_samples > 0\n",
    "\n",
    "    _, scores_max = batched_gen_and_disc(g_d_f, max_est_batches, batch_size)\n",
    "    scores_max = scores_max.max(axis=0)\n",
    "\n",
    "    #print('max scores')\n",
    "    #print(scores_max.to_string())\n",
    "\n",
    "    X = []\n",
    "    picked = [None] * n_samples\n",
    "    cap_out = [None] * n_samples\n",
    "    alpha = [None] * n_samples\n",
    "    picked_num = 0\n",
    "    all_generated_num = 0\n",
    "    for nn in tqdm(range(n_samples)):\n",
    "        X_, scores_fake_df = \\\n",
    "            batched_gen_and_disc(g_d_f, chain_batches, batch_size)\n",
    "        #print(f\"Shape of generated random images = {X_.shape}\")\n",
    "        picked_, cc, aa = \\\n",
    "            enhance_samples(scores_fake_df, scores_max, scores_real_df, clf_df,\n",
    "                            pickers=pickers)\n",
    "        picked_ = picked_.unstack()  # Convert to series\n",
    "        # Only save the used images for memory, so some index x-from needed\n",
    "        assert np.ndim(picked_.values) == 1\n",
    "        used_idx, idx_new = np.unique(picked_.values, return_inverse=True)\n",
    "        picked_ = pd.Series(data=idx_new, index=picked_.index)\n",
    "\n",
    "        # A bit of index manipulation in our memory saving scheme\n",
    "        picked[nn] = len(X) + picked_\n",
    "        add_X = list(X_[used_idx])\n",
    "        picked_num += len(add_X)\n",
    "        all_generated_num += len(X_)\n",
    "        #print(f\"number of selected images = {len(add_X)} out of {len(X_)}\")\n",
    "\n",
    "        X.extend(add_X)  # Unravel first index to list\n",
    "        cap_out[nn] = cc.unstack()\n",
    "        alpha[nn] = aa.unstack()\n",
    "\n",
    "    acceptence_rate = picked_num/all_generated_num\n",
    "    #print(f\"acceptance rate = {acceptence_rate}\")\n",
    "    X = np.asarray(X)\n",
    "    #assert X.ndim == 4\n",
    "    picked = pd.concat(picked, axis=1).T\n",
    "    assert picked.shape == (n_samples, len(picked_))\n",
    "    cap_out = pd.concat(cap_out, axis=1).T\n",
    "    assert cap_out.shape == (n_samples, len(picked_))\n",
    "    alpha = pd.concat(alpha, axis=1).T\n",
    "    assert alpha.shape == (n_samples, len(picked_))\n",
    "    return X, picked, cap_out, alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def mh_sampling(X_train, G, D, device, n_calib_pts, \n",
    "                batch_size_sample,\n",
    "                normalize_to_0_1=True,\n",
    "                type_calibrator='iso'):\n",
    "    calib_ids = np.random.choice(np.arange(X_train.shape[0]), n_calib_pts)\n",
    "    real_calib_data = [torch.FloatTensor(X_train[calib_ids])]\n",
    "\n",
    "    BASE_D = 'base'\n",
    "    scores_real = {}\n",
    "    scores_real[BASE_D] = np.concatenate([D(data.to(device)).detach().cpu().numpy()[:, 0] for data in real_calib_data])\n",
    "    if normalize_to_0_1:\n",
    "       scores_real[BASE_D] = expit(scores_real[BASE_D])\n",
    "    scores_real_df = validate_scores(scores_real)\n",
    "    n_real_batches, rem = divmod(len(scores_real[BASE_D]), batch_size_sample)\n",
    "\n",
    "    n_dim = X_train.shape[1]\n",
    "\n",
    "\n",
    "    def gen_disc_f(batch_size_fixed_):\n",
    "        noise = torch.randn(batch_size_fixed_, n_dim, device=device)\n",
    "        x = G(noise).detach()\n",
    "\n",
    "        scores = {BASE_D: D(x).detach().cpu().numpy()[:, 0]}\n",
    "        if normalize_to_0_1:\n",
    "           scores[BASE_D] = expit(scores[BASE_D])\n",
    "\n",
    "        x = x.cpu().numpy()\n",
    "        return x, scores\n",
    "\n",
    "    _, scores_fake_df = batched_gen_and_disc(gen_disc_f, n_real_batches, batch_size_sample)\n",
    "    ref_method = (BASE_D, 'raw')\n",
    "    incep_ref = BASE_D + '_iso_base'\n",
    "    #score_fname = os.path.join(outf, '%d_scores.csv' % epoch)\n",
    "    if type_calibrator=='iso':\n",
    "        calib_dict = {'iso': cl.Isotonic}\n",
    "    elif type_calibrator=='raw':\n",
    "        calib_dict = {'raw': cl.Identity}\n",
    "    elif type_calibrator=='linear':\n",
    "        calib_dict = {'linear': cl.Linear}\n",
    "    elif type_calibrator=='beta1':\n",
    "        calib_dict = {'beta1': cl.Beta1}\n",
    "    elif type_calibrator=='beta2':\n",
    "        calib_dict = {'beta2': cl.Beta2}\n",
    "    else:\n",
    "        raise TypeError('Unknown calibrator type')\n",
    "\n",
    "    #perf_report, calib_report, clf_df = \\\n",
    "    #    discriminator_analysis(scores_fake_df, scores_real_df, ref_method,\n",
    "    #                           dump_fname=score_fname)\n",
    "    pred_df_dump, clf_df = \\\n",
    "        discriminator_analysis(scores_fake_df, scores_real_df, ref_method,\n",
    "                                calib_dict=calib_dict)\n",
    "\n",
    "    #print('image dumps...')\n",
    "    # Some image dumps in case we want to actually look at generated images\n",
    "    pickers = {'MH': mh.mh_sample}\n",
    "    X, picked, cap_out, alpha = enhance_samples_series(gen_disc_f, \n",
    "                                                       scores_real_df, \n",
    "                                                       clf_df, \n",
    "                                                       pickers, \n",
    "                                                       n_samples=batch_size_sample)\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start to do MH sampling....\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-16bc16fa5e25>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Start to do MH sampling....\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtype_calibrator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'iso'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m X_mh = mh_sampling(X_train_scale, \n\u001b[0m\u001b[1;32m      9\u001b[0m                    \u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                    \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/myenv/lib/python3.8/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-ef0c93926dd4>\u001b[0m in \u001b[0;36mmh_sampling\u001b[0;34m(X_train, G, D, device, n_calib_pts, batch_size_sample, normalize_to_0_1, type_calibrator)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;31m#                           dump_fname=score_fname)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mpred_df_dump\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf_df\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         discriminator_analysis(scores_fake_df, scores_real_df, ref_method,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                 calib_dict=calib_dict)\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-044ca0c717b9>\u001b[0m in \u001b[0;36mdiscriminator_analysis\u001b[0;34m(scores_fake_df, scores_real_df, ref_method, calib_dict, dump_fname, label)\u001b[0m\n\u001b[1;32m     21\u001b[0m     '''\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# Build combined data set dataframe and train calibrators\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     pred_df, y_true = cl.combine_class_df(neg_class_df=scores_fake_df,\n\u001b[0m\u001b[1;32m     24\u001b[0m                                           pos_class_df=scores_real_df)\n\u001b[1;32m     25\u001b[0m     pred_df, y_true, clf_df = cl.calibrate_pred_df(pred_df, y_true, \n",
      "\u001b[0;32m~/gans-mcmc/tools/classification.py\u001b[0m in \u001b[0;36mcombine_class_df\u001b[0;34m(neg_class_df, pos_class_df)\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg_class_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_class_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;31m# Note nec always the case, but for now let's require balance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg_class_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_class_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mLABEL\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mneg_class_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if scaler is not None:\n",
    "    X_train_scale = scaler.transform(X_train)\n",
    "else:\n",
    "    X_train_scale = X_train\n",
    "\n",
    "print(\"Start to do MH sampling....\")\n",
    "type_calibrator = 'iso'\n",
    "X_mh = mh_sampling(X_train_scale, \n",
    "                   G, \n",
    "                   D, \n",
    "                   G.device, \n",
    "                   n_calib_pts, \n",
    "                   batch_size_sample=batch_size_sample,\n",
    "                   normalize_to_0_1=normalize_to_0_1,\n",
    "                   type_calibrator=type_calibrator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "calib_ids = np.random.choice(np.arange(X_train.shape[0]), n_calib_pts)\n",
    "real_calib_data = [torch.FloatTensor(X_train[calib_ids])]\n",
    "\n",
    "BASE_D = 'base'\n",
    "scores_real = {}\n",
    "scores_real[BASE_D] = np.concatenate([D(data.to(device)).detach().cpu().numpy()[:, 0] for data in real_calib_data])\n",
    "scores_real[BASE_D] = expit(scores_real[BASE_D])\n",
    "scores_real_df = validate_scores(scores_real)\n",
    "n_real_batches, rem = divmod(len(scores_real[BASE_D]), batch_size_sample)\n",
    "\n",
    "n_dim = X_train.shape[1]\n",
    "\n",
    "\n",
    "def gen_disc_f(batch_size_fixed_):\n",
    "    noise = torch.randn(batch_size_fixed_, n_dim, device=device)\n",
    "    x = G(noise).detach()\n",
    "\n",
    "    scores = {BASE_D: D(x).detach().cpu().numpy()[:, 0]}\n",
    "    if normalize_to_0_1:\n",
    "       scores[BASE_D] = expit(scores[BASE_D])\n",
    "\n",
    "    x = x.cpu().numpy()\n",
    "    return x, scores\n",
    "\n",
    "_, scores_fake_df = batched_gen_and_disc(gen_disc_f, n_real_batches, batch_size_sample)\n",
    "ref_method = (BASE_D, 'raw')\n",
    "incep_ref = BASE_D + '_iso_base'\n",
    "#score_fname = os.path.join(outf, '%d_scores.csv' % epoch)\n",
    "calib_dict = {'iso': cl.Isotonic}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>base</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.546832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.560116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.577192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.553612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.531129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>0.625313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>0.550318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>0.502336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>0.514151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>0.533626</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           base\n",
       "0      0.546832\n",
       "1      0.560116\n",
       "2      0.577192\n",
       "3      0.553612\n",
       "4      0.531129\n",
       "...         ...\n",
       "19995  0.625313\n",
       "19996  0.550318\n",
       "19997  0.502336\n",
       "19998  0.514151\n",
       "19999  0.533626\n",
       "\n",
       "[20000 rows x 1 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_fake_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>base</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.553219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.594622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.557208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.653977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.595332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24295</th>\n",
       "      <td>0.548325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24296</th>\n",
       "      <td>0.591191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24297</th>\n",
       "      <td>0.607150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24298</th>\n",
       "      <td>0.324111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24299</th>\n",
       "      <td>0.538650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24300 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           base\n",
       "0      0.553219\n",
       "1      0.594622\n",
       "2      0.557208\n",
       "3      0.653977\n",
       "4      0.595332\n",
       "...         ...\n",
       "24295  0.548325\n",
       "24296  0.591191\n",
       "24297  0.607150\n",
       "24298  0.324111\n",
       "24299  0.538650\n",
       "\n",
       "[24300 rows x 1 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_real_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
